{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TS-Group5/Capstone_Project/blob/main/resume_summery_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZaQdY3Xbd2K"
      },
      "outputs": [],
      "source": [
        "!pip -q install PyPDF2 python-docx torch transformers tqdm language-tool-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "ooUhxhKcl9ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from transformers import (\n",
        "    BartTokenizer,\n",
        "    BartForConditionalGeneration,\n",
        "    PegasusTokenizer,\n",
        "    PegasusForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    GPT2Tokenizer,\n",
        "    GPT2LMHeadModel,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "import PyPDF2\n",
        "from docx import Document\n",
        "import pathlib\n",
        "import language_tool_python\n",
        "\n",
        "# Constants\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MAX_LEN_INPUT = 512\n",
        "MAX_NEW_TOKENS = 200  # Increased token generation\n",
        "NUM_BEAMS = 4\n",
        "MODEL_SAVE_DIR = \"./fine_tuned_resume_models/\""
      ],
      "metadata": {
        "id": "KDkHVwVewgTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_resume_dataset(filepath):\n",
        "    \"\"\"\n",
        "    Load resume dataset from CSV with Category and Resume columns.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to the resume dataset CSV\n",
        "\n",
        "    Returns:\n",
        "        tuple: Lists of resume texts and corresponding categories/summaries\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Validate required columns\n",
        "        required_columns = ['Category', 'Resume']\n",
        "        if not all(col in df.columns for col in required_columns):\n",
        "            raise ValueError(f\"CSV must contain columns: {required_columns}\")\n",
        "\n",
        "        # Clean and preprocess data\n",
        "        resume_texts = df['Resume'].fillna('').apply(preprocess_resume_text).tolist()\n",
        "        categories = df['Category'].fillna('').tolist()\n",
        "\n",
        "        # Generate summary prompts based on categories\n",
        "        summaries = [f\"Professional summary for a {category} role\" for category in categories]\n",
        "\n",
        "        return resume_texts, summaries, categories\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {e}\")\n",
        "        return [], [], []"
      ],
      "metadata": {
        "id": "ccAMNK-EjA5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_resume_text(text):\n",
        "    \"\"\"Preprocess text by removing excessive whitespace and special characters.\"\"\"\n",
        "    cleaned_text = ' '.join(str(text).split()).replace('\\n', ' ')\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "exwVpNkAjONY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(texts, summaries, categories, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Split dataset into training and validation sets.\n",
        "\n",
        "    Args:\n",
        "        texts (list): List of resume texts\n",
        "        summaries (list): List of corresponding summaries\n",
        "        categories (list): List of resume categories\n",
        "        train_ratio (float): Ratio of training data (default: 0.8)\n",
        "\n",
        "    Returns:\n",
        "        tuple: Training and validation datasets with texts, summaries, and categories\n",
        "    \"\"\"\n",
        "    total_samples = len(texts)\n",
        "    train_size = int(total_samples * train_ratio)\n",
        "\n",
        "    # Create indices\n",
        "    torch.manual_seed(42)  # For reproducibility\n",
        "\n",
        "    # Shuffle indices\n",
        "    shuffled_indices = torch.randperm(total_samples).tolist()\n",
        "\n",
        "    # Split indices\n",
        "    train_indices = shuffled_indices[:train_size]\n",
        "    val_indices = shuffled_indices[train_size:]\n",
        "\n",
        "    # Create train and validation sets\n",
        "    train_texts = [texts[i] for i in train_indices]\n",
        "    train_summaries = [summaries[i] for i in train_indices]\n",
        "    train_categories = [categories[i] for i in train_indices]\n",
        "\n",
        "    val_texts = [texts[i] for i in val_indices]\n",
        "    val_summaries = [summaries[i] for i in val_indices]\n",
        "    val_categories = [categories[i] for i in val_indices]\n",
        "\n",
        "    return (train_texts, train_summaries, train_categories), (val_texts, val_summaries, val_categories)"
      ],
      "metadata": {
        "id": "HR_1ULz1jba8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_model():\n",
        "    \"\"\"Prompt the user to choose a summarization model.\"\"\"\n",
        "    print(\"Choose a summarization model:\")\n",
        "    print(\"1. Pegasus (google/pegasus-xsum)\")\n",
        "    print(\"2. BART (facebook/bart-large-cnn)\")\n",
        "    print(\"3. T5 (t5-small)\")\n",
        "    print(\"4. GPT-2 (gpt2)\")\n",
        "    choice = input(\"Enter the number of your choice (default: 2): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        model_name = \"google/pegasus-xsum\"\n",
        "        tokenizer_class = PegasusTokenizer\n",
        "        model_class = PegasusForConditionalGeneration\n",
        "    elif choice == \"3\":\n",
        "        model_name = \"t5-small\"\n",
        "        tokenizer_class = T5Tokenizer\n",
        "        model_class = T5ForConditionalGeneration\n",
        "    elif choice == \"4\":\n",
        "        model_name = \"gpt2\"\n",
        "        tokenizer_class = GPT2Tokenizer\n",
        "        model_class = GPT2LMHeadModel\n",
        "    else:\n",
        "        model_name = \"facebook/bart-large-cnn\"\n",
        "        tokenizer_class = BartTokenizer\n",
        "        model_class = BartForConditionalGeneration\n",
        "\n",
        "    return model_name, tokenizer_class, model_class\n"
      ],
      "metadata": {
        "id": "IZQ9NeZPjuip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Summary with Fine-tuned Model\n",
        "def summarize_text_with_prompt(model, tokenizer, text, prompt, max_len_input=512, max_new_tokens=150, device=\"cuda\"):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare input\n",
        "    full_input = f\"{prompt}\\n\\n{text}\"\n",
        "    input_ids = tokenizer.encode(full_input, max_length=max_len_input, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Create attention mask\n",
        "    attention_mask = torch.ones_like(input_ids).to(device)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        num_beams=NUM_BEAMS,\n",
        "        early_stopping=True,\n",
        "        pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\n",
        "    )\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "PUqqFQ5Cr3y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional grammar correction\n",
        "def correct_grammar(summary):\n",
        "    \"\"\"Post-process the generated summary for grammatical correctness.\"\"\"\n",
        "    try:\n",
        "        import language_tool_python\n",
        "        tool = language_tool_python.LanguageTool(\"en-US\")\n",
        "        matches = tool.check(summary)\n",
        "        corrected_summary = language_tool_python.utils.correct(summary, matches)\n",
        "        return corrected_summary\n",
        "    except Exception as e:\n",
        "        print(f\"Grammar correction failed: {e}\")\n",
        "        return summary"
      ],
      "metadata": {
        "id": "Rb4X9ySkr6UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResumeDataset(Dataset):\n",
        "    \"\"\"Dataset for fine-tuning summarization models.\"\"\"\n",
        "    def __init__(self, texts, summaries, tokenizer, max_len_input, max_len_output):\n",
        "        self.texts = texts\n",
        "        self.summaries = summaries\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len_input = max_len_input\n",
        "        self.max_len_output = max_len_output\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            max_length=self.max_len_input,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        target_encoding = self.tokenizer(\n",
        "            self.summaries[idx],\n",
        "            max_length=self.max_len_output,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": input_encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": input_encoding[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": target_encoding[\"input_ids\"].squeeze(),\n",
        "        }"
      ],
      "metadata": {
        "id": "eONJXO7DkLbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dynamic_prompts(categories):\n",
        "    \"\"\"\n",
        "    Create more descriptive and comprehensive prompts based on resume categories.\n",
        "\n",
        "    Args:\n",
        "        categories (list): List of resume categories\n",
        "\n",
        "    Returns:\n",
        "        dict: Mapping of categories to specific, detailed summary prompts\n",
        "    \"\"\"\n",
        "    dynamic_prompts = {}\n",
        "    for category in set(categories):\n",
        "        dynamic_prompts[category] = {\n",
        "            \"comprehensive\": f\"\"\"Craft a comprehensive professional summary for a {category} professional that:\n",
        "            - Highlights the most significant career achievements\n",
        "            - Details technical expertise and core competencies\n",
        "            - Emphasizes quantifiable impact and key performance metrics\n",
        "            - Showcases unique value proposition in the {category} domain\n",
        "            - Provides a strategic overview of professional growth and potential\"\"\",\n",
        "\n",
        "            \"experience_focused\": f\"\"\"Generate an experience-driven summary for a {category} professional that:\n",
        "            - Chronologically highlights career progression\n",
        "            - Describes pivotal roles and transformative projects\n",
        "            - Quantifies professional accomplishments with specific metrics\n",
        "            - Illustrates technical skills and industry expertise\n",
        "            - Demonstrates leadership and innovation in the {category} field\"\"\",\n",
        "\n",
        "            \"skills_and_impact\": f\"\"\"Create a skills-centric summary for a {category} professional that:\n",
        "            - Lists advanced technical and soft skills\n",
        "            - Connects skills to tangible business outcomes\n",
        "            - Highlights certifications and specialized training\n",
        "            - Demonstrates versatility and adaptability\n",
        "            - Shows potential for driving organizational success in {category} roles\"\"\",\n",
        "\n",
        "            \"strategic_profile\": f\"\"\"Develop a strategic professional profile for a {category} expert that:\n",
        "            - Provides a holistic view of professional capabilities\n",
        "            - Connects past experiences to future potential\n",
        "            - Highlights innovative approaches and problem-solving skills\n",
        "            - Demonstrates industry thought leadership\n",
        "            - Articulates unique professional narrative in the {category} space\"\"\"\n",
        "        }\n",
        "    return dynamic_prompts"
      ],
      "metadata": {
        "id": "yPa5SLP8wnOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model_with_dataset(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    train_texts,\n",
        "    train_summaries,\n",
        "    val_texts=None,\n",
        "    val_summaries=None,\n",
        "    max_len_input=512,\n",
        "    max_len_output=150,\n",
        "    epochs=3,\n",
        "    batch_size=4,\n",
        "    model_name=\"resume_summary_model\",\n",
        "    stop_loss_threshold=0.5\n",
        "):\n",
        "    \"\"\"\n",
        "    Enhanced fine-tuning with model saving and optional validation.\n",
        "    \"\"\"\n",
        "    # Ensure model save directory exists\n",
        "    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = ResumeDataset(train_texts, train_summaries, tokenizer, max_len_input, max_len_output)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Optional validation dataset\n",
        "    val_loader = None\n",
        "    if val_texts and val_summaries:\n",
        "        val_dataset = ResumeDataset(val_texts, val_summaries, tokenizer, max_len_input, max_len_output)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Training setup\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        # Training loop\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels,\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Validation if loader exists\n",
        "        if val_loader:\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for batch in val_loader:\n",
        "                    input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "                    attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "                    labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "                    outputs = model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        labels=labels,\n",
        "                    )\n",
        "                    val_loss += outputs.loss.item()\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            print(f\"Epoch {epoch+1}: Train Loss = {train_loss/len(train_loader):.4f}, \"\n",
        "                  f\"Validation Loss = {val_loss:.4f}\")\n",
        "\n",
        "            # Save the best model based on validation loss\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                model_save_path = os.path.join(MODEL_SAVE_DIR, f\"{model_name}_best.pt\")\n",
        "                torch.save({\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': best_val_loss\n",
        "                }, model_save_path)\n",
        "                print(f\"Saved best model to {model_save_path}\")\n",
        "        else:\n",
        "            print(f\"Epoch {epoch+1}: Train Loss = {train_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(MODEL_SAVE_DIR, f\"{model_name}_final.pt\")\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, final_model_path)\n",
        "    print(f\"Final model saved to {final_model_path}\")\n",
        "\n",
        "    print(\"Fine-tuning complete!\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "9fUVeOe_wswr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Kaggle Dataset Path\n",
        "    kaggle_dataset_path = input(\"Enter path to resume dataset CSV: \").strip()\n",
        "\n",
        "    # Load Dataset\n",
        "    resume_texts, summaries, categories = load_resume_dataset(kaggle_dataset_path)\n",
        "\n",
        "    if not resume_texts:\n",
        "        print(\"No valid resume data found.\")\n",
        "        return\n",
        "\n",
        "    # Create dynamic prompts based on categories\n",
        "    dynamic_prompts = create_dynamic_prompts(categories)\n",
        "\n",
        "    # Split Dataset\n",
        "    (train_texts, train_summaries, train_categories), (val_texts, val_summaries, val_categories) = split_dataset(\n",
        "        resume_texts, summaries, categories\n",
        "    )\n",
        "\n",
        "    # Choose Model\n",
        "    model_name, tokenizer_class, model_class = choose_model()\n",
        "    tokenizer = None\n",
        "    if model_name == 't5-small':\n",
        "        tokenizer = tokenizer_class.from_pretrained(model_name, legacy=False)\n",
        "    else:\n",
        "        tokenizer = tokenizer_class.from_pretrained(model_name)\n",
        "    model = model_class.from_pretrained(model_name).to(DEVICE)\n",
        "\n",
        "    # Fine-tune Model\n",
        "    fine_tuned_model = fine_tune_model_with_dataset(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        train_texts,\n",
        "        train_summaries,\n",
        "        val_texts,\n",
        "        val_summaries,\n",
        "        model_name=model_name.replace('/', '_'),\n",
        "        stop_loss_threshold=0.5\n",
        "    )\n",
        "\n",
        "    # Resume Path for Summary Generation\n",
        "    resume_path = input(\"Enter the path to the resume file to generate summary: \").strip()\n",
        "    resume_category = input(\"Enter the category for this resume (e.g., Java Developer, Data Scientist): \").strip()\n",
        "\n",
        "    # Extract text (function remains the same as in previous script)\n",
        "    def extract_text(resume_path):\n",
        "        import os\n",
        "        import PyPDF2\n",
        "        from docx import Document\n",
        "\n",
        "        file_extension = os.path.splitext(resume_path)[1].lower()\n",
        "\n",
        "        try:\n",
        "            if file_extension == '.pdf':\n",
        "                with open(resume_path, \"rb\") as file:\n",
        "                    pdf_reader = PyPDF2.PdfReader(file)\n",
        "                    text = \"\"\n",
        "                    for page in pdf_reader.pages:\n",
        "                        text += page.extract_text() + \"\\n\"\n",
        "                    return text.strip()\n",
        "            elif file_extension in ['.docx', '.doc']:\n",
        "                doc = Document(resume_path)\n",
        "                text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
        "                return text.strip()\n",
        "            else:\n",
        "                with open(resume_path, 'r', encoding='utf-8') as file:\n",
        "                    return file.read().strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            return None\n",
        "\n",
        "    resume_text = extract_text(resume_path)\n",
        "\n",
        "    if not resume_text or not resume_text.strip():\n",
        "        print(\"Failed to extract text or the file is empty.\")\n",
        "        return\n",
        "\n",
        "    # Prompt selection\n",
        "    print(\"\\nSelect summary format:\")\n",
        "    category_prompts = dynamic_prompts.get(resume_category, dynamic_prompts.get('default', {}))\n",
        "\n",
        "    if not category_prompts:\n",
        "        category_prompts = {\n",
        "            \"comprehensive\": f\"Generate a comprehensive summary for a {resume_category} professional.\",\n",
        "            \"experience_focused\": f\"Create an experience-driven summary for a {resume_category} role.\",\n",
        "            \"skills_and_impact\": f\"Develop a skills-centric profile for a {resume_category} professional.\",\n",
        "            \"strategic_profile\": f\"Craft a strategic overview for a {resume_category} expert.\"\n",
        "        }\n",
        "\n",
        "    for i, (key, desc) in enumerate(category_prompts.items(), 1):\n",
        "        print(f\"{i}. {desc}\")\n",
        "\n",
        "    choice = int(input(\"Enter the number of your choice: \").strip()) - 1\n",
        "    prompt_key = list(category_prompts.keys())[choice]\n",
        "    prompt = category_prompts[prompt_key]\n",
        "\n",
        "  # Generate summary (same as before)\n",
        "    summary = summarize_text_with_prompt(\n",
        "        fine_tuned_model,\n",
        "        tokenizer,\n",
        "        resume_text,\n",
        "        prompt,\n",
        "        MAX_LEN_INPUT,\n",
        "        MAX_NEW_TOKENS,\n",
        "        DEVICE\n",
        "    )\n",
        "\n",
        "    # Grammar correction (same as before)\n",
        "    summary = correct_grammar(summary)\n",
        "    print(f\"\\nGenerated Summary ({prompt_key.capitalize()}):\\n\", summary)\n",
        "\n",
        "    # Save Summary\n",
        "    output_path = f\"{resume_path.rsplit('.', 1)[0]}_{resume_category}_{prompt_key}_summary.txt\"\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(summary)\n",
        "    print(f\"\\nSummary saved to: {output_path}\")\n",
        "\n",
        "    # Retrain with new resume data\n",
        "    retrain_choice = input(\"Do you want to retrain the model with this new resume? (yes/no): \").strip().lower()\n",
        "    if retrain_choice == 'yes':\n",
        "        # Prepare new training data\n",
        "        new_train_texts = train_texts + [resume_text]\n",
        "        new_train_summaries = train_summaries + [summary]\n",
        "\n",
        "        # Fine-tune model again with new data\n",
        "        fine_tuned_model = fine_tune_model_with_dataset(\n",
        "            fine_tuned_model,\n",
        "            tokenizer,\n",
        "            new_train_texts,\n",
        "            new_train_summaries,\n",
        "            val_texts,\n",
        "            val_summaries,\n",
        "            model_name=f\"{model_name.replace('/', '_')}_updated\"\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "p7Of2KZ8xvpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text-to-Audio** - Working\n",
        "\n"
      ],
      "metadata": {
        "id": "9lmE_naWz7PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install torch torchaudio transformers TTS soundfile speechbrain"
      ],
      "metadata": {
        "id": "nvrBWEXjz8x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install git+https://github.com/speechbrain/speechbrain\n",
        "!pip -q install speechbrain"
      ],
      "metadata": {
        "id": "2DAvUllRZyID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.pretrained import Tacotron2, HIFIGAN\n",
        "import torchaudio\n",
        "\n",
        "# Load pre-trained TTS model\n",
        "tacotron2 = Tacotron2.from_hparams(source=\"speechbrain/tts-tacotron2-ljspeech\", savedir=\"tmpdir_tts\")\n",
        "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", savedir=\"tmpdir_vocoder\")\n",
        "\n",
        "# Input text\n",
        "text = \"Hello, this is a text-to-audio conversion example using machine learning.\"\n",
        "\n",
        "# Generate mel-spectrogram from text\n",
        "mel_output, _, _ = tacotron2.encode_text(text)\n",
        "\n",
        "# Generate audio waveform from mel-spectrogram\n",
        "waveforms = hifi_gan.decode_batch(mel_output)\n",
        "\n",
        "# Save to a file\n",
        "torchaudio.save(\"output_audio.wav\", waveforms.squeeze(1), 22050)\n",
        "\n",
        "print(\"Audio saved to output_audio.wav\")\n"
      ],
      "metadata": {
        "id": "4gHyQnzc0IG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **USING Mozilla TTS** - Inprogress"
      ],
      "metadata": {
        "id": "P4NJM0WccwDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install TTS"
      ],
      "metadata": {
        "id": "a0T22Lhec82T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import TTS\n",
        "from TTS.api import TTS\n",
        "\n",
        "# Initialize the TTS model\n",
        "try:\n",
        "    #tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=True, gpu=False)\n",
        "    tts = TTS(model_name=\"tts_models/multispeaker/en/vctk\", progress_bar=True, gpu=False)\n",
        "    # Check if speakers are available\n",
        "    speakers = tts.speakers if hasattr(tts, 'speakers') else []\n",
        "\n",
        "    if speakers:\n",
        "        print(\"Available speakers:\", speakers)\n",
        "\n",
        "        # Choose a speaker\n",
        "        speaker = input(\"Enter the speaker name from the above list (or press Enter for default): \") or speakers[0]\n",
        "    else:\n",
        "        print(\"No multiple speakers available for this model.\")\n",
        "        speaker = None\n",
        "\n",
        "    # Input text\n",
        "    text = input(\"Enter the text to synthesize: \")\n",
        "\n",
        "    # Generate speech\n",
        "    output_path = \"output_audio.wav\"\n",
        "\n",
        "    # Handle speaker parameter differently based on availability\n",
        "    if speaker:\n",
        "        tts.tts_to_file(text=text, speaker=speaker, file_path=output_path)\n",
        "    else:\n",
        "        tts.tts_to_file(text=text, file_path=output_path)\n",
        "\n",
        "    print(f\"Audio saved to {output_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"Please check:\")\n",
        "    print(\"1. Is the TTS library installed correctly?\")\n",
        "    print(\"2. Are you using the latest version of the TTS library?\")\n",
        "    print(\"3. Is the model name correct?\")"
      ],
      "metadata": {
        "id": "nIQQhdNac4vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using PYTTSX** - Inprogress"
      ],
      "metadata": {
        "id": "vurR-cR1hjbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pyttsx3"
      ],
      "metadata": {
        "id": "seiREXaMhp_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyttsx3\n",
        "import os\n",
        "\n",
        "def save_audio(text, voice_gender='male', filename='output.mp3'):\n",
        "    engine = pyttsx3.init()\n",
        "\n",
        "    # Get available voices\n",
        "    voices = engine.getProperty('voices')\n",
        "\n",
        "    # Validate and select the voice based on gender\n",
        "    if voice_gender == 'male':\n",
        "        voice_index = 17\n",
        "    elif voice_gender == 'female':\n",
        "        voice_index = 12\n",
        "    else:\n",
        "        print(\"Invalid voice gender specified. Use 'male' or 'female'.\")\n",
        "        return\n",
        "\n",
        "    # Validate voice index\n",
        "    if voice_index < 0 or voice_index >= len(voices):\n",
        "        print(f\"Voice index {voice_index} is out of range. Check available voices.\")\n",
        "        return\n",
        "\n",
        "    selected_voice = voices[voice_index]\n",
        "    engine.setProperty('voice', selected_voice.id)\n",
        "    print(f\"Selected voice: {selected_voice.name} (ID: {selected_voice.id})\")\n",
        "\n",
        "    # Adjust speech properties\n",
        "    engine.setProperty('rate', 200)  # Speaking rate\n",
        "    engine.setProperty('volume', 1.0)  # Volume (0.0 to 1.0)\n",
        "\n",
        "    # Ensure the output file does not already exist\n",
        "    if os.path.exists(filename):\n",
        "        os.remove(filename)\n",
        "\n",
        "    # Split the text into chunks (optional)\n",
        "    chunk_size = 100  # Adjust as needed\n",
        "    text_chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "    # Save audio for each chunk\n",
        "    for i, chunk in enumerate(text_chunks):\n",
        "        temp_filename = f\"temp_chunk_{i}.mp3\"\n",
        "        print(f\"Saving chunk {i+1}: {chunk}\")\n",
        "        engine.save_to_file(chunk, temp_filename)\n",
        "        engine.runAndWait()\n",
        "\n",
        "        # Optionally, append chunks into the final file (if needed)\n",
        "        # If saving in the same file, you could use a library like `pydub` to merge audio files.\n",
        "\n",
        "    print(f\"Final audio saved as {filename}\")\n",
        "\n",
        "# Example usage\n",
        "text = \"Hello! This is a text-to-speech conversion example to verify the correct voice and text handling.\"\n",
        "\n",
        "# Save audio with male voice\n",
        "save_audio(text, 'male', 'male_voice.mp3')\n",
        "\n",
        "# Save audio with female voice\n",
        "save_audio(text, 'female', 'female_voice.mp3')\n"
      ],
      "metadata": {
        "id": "eHca3TdVj6Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Play the Generated Audio** - Not Required"
      ],
      "metadata": {
        "id": "1usKEBmF0U78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libportaudio2 # install the portaudio dependency\n",
        "!pip -q install sounddevice # install the sounddevice library"
      ],
      "metadata": {
        "id": "EdojcpV01SF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Load the generated audio\n",
        "y, sr = librosa.load(\"output_audio.wav\", sr=None)\n",
        "\n",
        "# Lower the pitch (-4 semitones for male-like voice)\n",
        "y_lowered = librosa.effects.pitch_shift(y, sr, n_steps=-4)\n",
        "\n",
        "# Save the modified audio\n",
        "sf.write(\"male_voice.wav\", y_lowered, sr)\n",
        "\n",
        "print(\"Modified audio saved as 'male_voice.wav'\")"
      ],
      "metadata": {
        "id": "UY8C9itX2d6Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}